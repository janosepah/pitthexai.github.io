<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Ahmad P. Tafti, Ahmad Tafti, Pitt HexAI, Pitt HexAI Research Laboratory">
    <meta name="keywords" content="Ahmad P. Tafti, Ahmad Tafti, Pitt HexAI, Pitt HexAI Research Laboratory, Explainable AI, Total Joint Arthroplasty, AI in Healthcare, HexAI, Health and Explainable AI, Explainable, Interpretable, and Accountable AI, University of Pittsburgh">
    <meta name="author" content="Ahmad P. Tafti">
    <title>Research | Pitt HexAI Research Laboratory</title>
  

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Roboto:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: BizLand - v3.9.1
  * Template URL: https://bootstrapmade.com/bizland-bootstrap-business-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Top Bar ======= -->
  <section id="topbar" class="d-flex align-items-center">
    <div class="container d-flex justify-content-center justify-content-md-between">
      <div class="social-links d-none d-md-flex align-items-center">
      </div>
	  <div class="contact-info d-flex align-items-center ">
        <a href="https://www.pitt.edu/" target="_blank" class="text-light">University of Pittsburgh</a>
      </div>
    </div>
  </section>

  <!-- ======= Header ======= -->
  <header id="header" class="d-flex align-items-center">
    <div class="container d-flex align-items-center justify-content-between">

      <h1 class="logo"><a href="index.html"><img src="assets/img/Pitthexai_logo.png"  class="logo"></a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt=""></a>-->

       <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto " href="index.html"><i class="bx bx-home"></i> Home</a></li>
          <li><a class="nav-link scrollto" href="people.html"><i class="bx bx-user"></i> People</a></li>
          <li><a class="nav-link scrollto active" href="research.html"><i class="bx bx-search"></i> Research</a></li>
          <li><a class="nav-link scrollto " href="publications.html"><i class="bx bx-book"></i> Publications</a></li>
          <li><a class="nav-link scrollto " href="events.html"><i class="bx bx-calendar"></i> Events</a></li>
          <li><a class="nav-link scrollto " href="openings.html"><i class="bx bx-bookmark-alt-plus"></i> Openings</a></li>
          <li><a class="nav-link scrollto" href="funding.html"><i class="bx bx-receipt"></i> Funding</a></li>
          <li><a class="nav-link scrollto" href="githubrepo.html"><i class="bx bx-code"></i> GitHub Repositories</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <main id="main" data-aos="fade-up">

    <!-- ======= Breadcrumbs ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2><strong>Research</strong></h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li>Research</li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

	  
	  
	  
    <section id="about" class="about">
      <div class="container" data-aos="fade-up">
	               
       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>An Ensemble Machine Learning Method to Predict Unplanned Return to Operating Room Following Primary Total Shoulder Arthroplasty</h3>
            <p >
              Reoperation is the most significant compilation following any surgical procedure. Developing machine learning methods that can predict the need for reoperation will allow for improved shared surgical decision making, and patient-specific and preoperative optimization. Yet, no precise machine learning models have been published to perform well in predicting the need for a reoperation within 30-days following primary total shoulder arthroplasty (TSA). This study aimed to build, train, and evaluate an ensemble machine learning method that predicts return to the operating room following primary TSA with an accuracy of 0.852 and AUC of 0.91. 
            </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/tsa.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>
	  
	  
	  <section id="about" class="about">
      <div class="container" data-aos="fade-up">
	               
       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>An Ensemble Machine Learning Method to Predict Unplanned Return to Operating Room Following Primary Total Shoulder Arthroplasty</h3>
            <p >
              Knee range of motion is an important indicator of function in both the native and surgically replaced knee. In the clinical setting, range of motion can be adequately evaluated by the surgeon either visually or with the assistance of a goniometer. Comparatively, patients may not be as experienced in estimating their knee range of motion (ROM) outside of clinic or the hospital. Developing a mobile application through which patients can easily assess their knee ROM may provide a more accessible tool for measuring progress in regaining function. The purpose of this study was to validate a mobile phone application developed to measure knee ROM, when compared to visual-based and goniometer-based ROM measurements obtained in an Orthopedic clinic setting.
            </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/kneerom.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>
	
    <section id="about" class="about section-bg">
      <div class="container" data-aos="fade-up">

       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Word Embedding Neural Networks to Advance Knee Osteoarthritis Research</h3>
            <p >
              Osteoarthritis (OA) is the most prevalent chronic joint disease worldwide, where knee OA takes more than 80% of commonly affected joints. Knee OA is not a curable disease yet, and it affects large columns of patients, making it costly to patients and healthcare systems. Etiology, diagnosis, and treatment of knee OA might be argued by variability in its clinical and physical manifestations. Although knee OA carries a list of well-known terminology aiming to standardize the nomenclature of the diagnosis, prognosis, treatment, and clinical outcomes of the chronic joint disease, in practice there is a wide range of terminology associated with knee OA across different data sources, including but not limited to biomedical literature, clinical notes, healthcare literacy, and health-related social media. Among these data sources, the scientific articles published in the biomedical literature usually make a principled pipeline to study disease. Rapid yet, accurate text mining on large-scale scientific literature may discover novel knowledge and terminology to better understand knee OA and to improve the quality of knee OA diagnosis, prevention, and treatment. The present works aim to utilize artificial neural network strategies to automatically extract vocabularies associated with knee OA diseases. Our finding indicates the feasibility of developing word embedding neural networks for autonomous keyword extraction and abstraction of knee OA.
			  </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/wordembedding.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>
	
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	
    <section id="about" class="about section-bg">
      <div class="container" data-aos="fade-up">

       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Word Embedding Neural Networks to Advance Knee Osteoarthritis Research</h3>
            <p >
              Osteoarthritis (OA) is the most prevalent chronic joint disease worldwide, where knee OA takes more than 80% of commonly affected joints. Knee OA is not a curable disease yet, and it affects large columns of patients, making it costly to patients and healthcare systems. Etiology, diagnosis, and treatment of knee OA might be argued by variability in its clinical and physical manifestations. Although knee OA carries a list of well-known terminology aiming to standardize the nomenclature of the diagnosis, prognosis, treatment, and clinical outcomes of the chronic joint disease, in practice there is a wide range of terminology associated with knee OA across different data sources, including but not limited to biomedical literature, clinical notes, healthcare literacy, and health-related social media. Among these data sources, the scientific articles published in the biomedical literature usually make a principled pipeline to study disease. Rapid yet, accurate text mining on large-scale scientific literature may discover novel knowledge and terminology to better understand knee OA and to improve the quality of knee OA diagnosis, prevention, and treatment. The present works aim to utilize artificial neural network strategies to automatically extract vocabularies associated with knee OA diseases. Our finding indicates the feasibility of developing word embedding neural networks for autonomous keyword extraction and abstraction of knee OA.
			  </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/wordembedding.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>
	  
	  
	  
	  
	   <section id="about" class="about">
      <div class="container" data-aos="fade-up">
	               
       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Give Me a Knee Radiograph, I Will Show You Where the Knee Joint Space Is: Enforcing Few-Sample Learning for Knee Semantic Segmentation</h3>
            <p >
              From the computational perspective, deep learning computer vision methods have already demonstrated very successful applications in a variety of medical image analysis tasks. However, there are several fundamental challenges that stop deep learning methods to obtain their full potential in healthcare settings. One can see that they often need a large column of annotated training data to achieve better accuracy over traditional machine learning methods. The current work tends to use deep few-shot learning to tackle the problem of knee joint space segmentation in plain radiographs using only few samples of manually segmented radiographs.
            </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/beth.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>
	
    <section id="about" class="about section-bg">
      <div class="container" data-aos="fade-up">

       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Give Me a Knee Radiograph, I Will Tell You Where the Knee Joint Area Is</h3>
            <p >
              Knee pain is clinically evaluated by routine radiographs, where the widespread adoption of radiographic images and their availability at low cost, make them the principle component in the assessment of knee pain and knee pathologies. The current work proposes an accurate and effective pipeline for autonomous detection, localization, and classification of knee joint area in plain radiographs combining the You Only Look Once (YOLO v3) deep convolutional neural network with a large and fully-annotated knee radiographs dataset.
			  </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/kneeyolo.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>

	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	  
	
    <section id="about" class="about">
      <div class="container" data-aos="fade-up">

       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>DeepTKAClassifier: Brand Classification of Total Knee Arthroplasty Implants using Explainable Deep Convolutional Neural Networks</h3>
            <p >
              Total knee arthroplasty (TKA) is one of the most successful surgical procedures worldwide. It improves quality of life, mobility, and functionality for the vast majority of patients. However, a TKA surgery may fail over time for several reasons, thus it requires a revision arthroplasty surgery. Identifying TKA implants is a critical consideration in preoperative planning of revision surgery. This study aims to develop, train, and validate deep convolutional neural network models to precisely classify four widely-used TKA implants based on only plain knee radiographs. Using 9,052 computationally annotated knee radiographs, we achieved weighted average precision, recall, and F1-score of 0.97, 0.97, and 0.97, respectively, with Cohen Kappa of 0.96.
			  </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/deeptka.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>
	
    <section id="about" class="about section-bg">
      <div class="container" data-aos="fade-up">

       
        <div class="row">
          <div class="col-lg-9 pt-4 pt-lg-0 content d-flex flex-column justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>NLP-Powered Algorithms to Identify Common Data Elements in Operative Notes for Knee Arthroplasty</h3>
            <p >
              Within a cohort of 20,000 knee arthroplasty operative notes from 2000 to 2017 at a large tertiary institution, we randomly selected independent pairs of training and test sets to develop and evaluate NLP algorithms to detect five major data elements. The size of the training and test datasets were similar and ranged between 420 to 1592 surgeries. Expert rules using keywords in operative notes were used to implement NLP algorithms capturing: (1) category of surgery (total knee arthroplasty, unicompartmental knee arthroplasty, patellofemoral arthroplasty), (2) laterality of surgery, (3) constraint type, (4) presence of patellar resurfacing, and (5) implant model (catalog numbers). We used institutional registry data as our gold standard to evaluate the NLP algorithms. It achieved 98.3%, 99.5%, 99.2%, and 99.4% accuracy on test datasets, respectively. The implant model algorithm achieved an F1-score of 99.9%.
			  </p>
          </div>
          <div class="col-lg-3" data-aos="fade-right" data-aos-delay="100">
            <img src="assets/img/research/operativenotes.png" class="img-fluid mt-3" alt="">
          </div>
        </div>

      </div>
    </section>

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">

<div class="footer-newsletter" style="padding: 10px 0;"></div>

    <div class="footer-top">
      <div class="container">
        <div class="row">

          <div class="col-md-4 footer-contact">
            <img src="assets/img/Pitthexai_logo.png" class="rounded footer-img">
          </div>

          <div class="col-md-4 footer-links">
            <h4>Address</h4>
            <p>University of Pittsburgh<br>
School of Health and Rehabilitation Sciences<br>
Department of Health Informatics<br>
6030 Forbes Tower<br>
Pittsburgh, PA 15260</p>
          </div>

          <div class="col-md-4 footer-links">
            <h4>Contact</h4>
<p>Email: tafti[dot]ahmad[at]pitt.edu<br></p>
          </div>

        </div>
      </div>
    </div>

    <div class="container py-4">
      <div class="copyright">
        &copy; Copyright <strong><span>Pitt Health + Explainable AI (Pitt HexAI) Research Laboratory</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
      </div>
    </div>
  </footer><!-- End Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
